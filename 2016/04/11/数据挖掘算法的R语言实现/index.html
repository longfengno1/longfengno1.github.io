<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="R语言," />





  <link rel="alternate" href="/atom.xml" title="Xiao's Note" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.5.0" />






<meta name="description" content="前言学习数据挖掘已经有一段时间了，相关的文章和书也看了一些，感觉学习这个的关键还是离不开其中形形色色的算法。作为一个初学者，我们也不奢求创新改进个算法。先从基础做起，学会各个基础算法的思想与实现。学习算法的过程是十分枯燥的，但是如果学习的过程能够实践，例如使用R语言实践一下，将一堆头痛眼花的数据转化成一张炫酷的图，这无疑是十分有成就感的。所以，我就最近学习的资料，整理了一些算法与R语言的实现方法分">
<meta property="og:type" content="article">
<meta property="og:title" content="数据挖掘算法的R语言实现">
<meta property="og:url" content="https://longfengno1.github.io/2016/04/11/数据挖掘算法的R语言实现/index.html">
<meta property="og:site_name" content="Xiao's Note">
<meta property="og:description" content="前言学习数据挖掘已经有一段时间了，相关的文章和书也看了一些，感觉学习这个的关键还是离不开其中形形色色的算法。作为一个初学者，我们也不奢求创新改进个算法。先从基础做起，学会各个基础算法的思想与实现。学习算法的过程是十分枯燥的，但是如果学习的过程能够实践，例如使用R语言实践一下，将一堆头痛眼花的数据转化成一张炫酷的图，这无疑是十分有成就感的。所以，我就最近学习的资料，整理了一些算法与R语言的实现方法分">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1863202-0377acaefc8ac97d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1863202-060c899e0b5b0022.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1863202-2128ea9d6676999a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2016-04-12T06:01:11.884Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="数据挖掘算法的R语言实现">
<meta name="twitter:description" content="前言学习数据挖掘已经有一段时间了，相关的文章和书也看了一些，感觉学习这个的关键还是离不开其中形形色色的算法。作为一个初学者，我们也不奢求创新改进个算法。先从基础做起，学会各个基础算法的思想与实现。学习算法的过程是十分枯燥的，但是如果学习的过程能够实践，例如使用R语言实践一下，将一堆头痛眼花的数据转化成一张炫酷的图，这无疑是十分有成就感的。所以，我就最近学习的资料，整理了一些算法与R语言的实现方法分">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/1863202-0377acaefc8ac97d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>

  <title> 数据挖掘算法的R语言实现 | Xiao's Note </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?bcaf41ccdd04415f1afd2b5d862e23ec";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Xiao's Note</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
  <a id="translateLink" href="javascript:translatePage();">繁體</a>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-th fa-fw"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user fa-fw"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                数据挖掘算法的R语言实现
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-04-11T09:24:27+08:00" content="2016-04-11">
              2016-04-11
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/数据挖掘/" itemprop="url" rel="index">
                    <span itemprop="name">数据挖掘</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/04/11/数据挖掘算法的R语言实现/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/04/11/数据挖掘算法的R语言实现/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/04/11/数据挖掘算法的R语言实现/" class="leancloud_visitors" data-flag-title="数据挖掘算法的R语言实现">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye">
				 </i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>学习数据挖掘已经有一段时间了，相关的文章和书也看了一些，感觉学习这个的关键还是离不开其中形形色色的算法。作为一个初学者，我们也不奢求创新改进个算法。先从基础做起，学会各个基础算法的思想与实现。学习算法的过程是十分枯燥的，但是如果学习的过程能够实践，例如使用R语言实践一下，将一堆头痛眼花的数据转化成一张炫酷的图，这无疑是十分有成就感的。所以，我就最近学习的资料，整理了一些算法与R语言的实现方法分享一下。由于篇幅的问题，后面提到的函数我都没有详细介绍了，想了解的可以使用<code>&gt;?函数名</code>或<code>&gt;??函数名</code>查看。<br><a id="more"></a></p>
<h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><h2 id="1、KNN算法"><a href="#1、KNN算法" class="headerlink" title="1、KNN算法"></a>1、KNN算法</h2><p>K——最临近方法（k Nearest Neighbors，简称KNN）是实际运用中经常被采用的一种基于距离的分类算法。</p>
<p>基本思想：<br>假定每个类包含多个训练数据，且每个训练数据都有一个唯一的类别标记，计算每个训练数据到待分类元组的距离，取和待分类元组距离最近的k个训练数据，k个数据中哪个类别的训练数据占多数，则待分类元组就属于哪个类别。</p>
<p>主要函数：</p>
<blockquote>
<p>knn()</p>
</blockquote>
<p>加载R中的class库：</p>
<blockquote>
<p>> library(class)</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; data(iris3)</span><br><span class="line"><span class="comment">#选取前30个数据作为训练数据</span></span><br><span class="line">&gt; train&lt;-rbind(iris[<span class="number">1</span>:<span class="number">30</span>,,<span class="number">1</span>],iris[<span class="number">1</span>:<span class="number">30</span>,,<span class="number">2</span>],iris[<span class="number">1</span>:<span class="number">30</span>,,<span class="number">3</span>])</span><br><span class="line"><span class="comment">#剩下的作为测试数据</span></span><br><span class="line">&gt; test&lt;-rbind(iris[<span class="number">31</span>:<span class="number">50</span>,,<span class="number">1</span>],iris[<span class="number">31</span>:<span class="number">50</span>,,<span class="number">2</span>],iris[<span class="number">31</span>:<span class="number">50</span>,,<span class="number">3</span>])</span><br><span class="line">&gt; c1&lt;-factor(c(rep(<span class="string">"s"</span>,<span class="number">30</span>),rep(<span class="string">"c"</span>,<span class="number">30</span>),rep(<span class="string">"v"</span>,<span class="number">30</span>)))</span><br><span class="line"><span class="comment">#进行KNN算法分类</span></span><br><span class="line">&gt; knn(train,test,c1,k=<span class="number">3</span>,prob=<span class="literal">TRUE</span>)</span><br><span class="line">&gt; attributes(.Last.value)</span><br></pre></td></tr></table></figure></p>
<h2 id="2、决策树算法（C4-5）"><a href="#2、决策树算法（C4-5）" class="headerlink" title="2、决策树算法（C4,5）"></a>2、决策树算法（C4,5）</h2><p>主要函数：</p>
<blockquote>
<p>J48()</p>
</blockquote>
<p>准备工作：</p>
<blockquote>
<p>> install.packages(‘rJava’)<br>> install.packages(‘party’)<br>> install.packages(‘RWeka’)<br>> install.packages(‘partykit’)<br>> library(RWeka)<br>> library(party)</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; oldpar=par(mar=c(<span class="number">3</span>,<span class="number">3</span>,<span class="number">1.5</span>,<span class="number">1</span>),mgp=c(<span class="number">1.5</span>,<span class="number">0.5</span>,<span class="number">0</span>),cex=<span class="number">0.3</span>)</span><br><span class="line">&gt; data(iris)</span><br><span class="line">&gt; m1&lt;-J48(Species~.,data=iris)</span><br><span class="line">&gt; m1</span><br><span class="line">&gt; table(iris$Species,predict(m1))</span><br><span class="line">&gt; write_to_dot(m1)</span><br><span class="line">&gt; <span class="keyword">if</span>(<span class="keyword">require</span>(<span class="string">"party"</span>,quietly=<span class="literal">TRUE</span>)) plot(m1)</span><br></pre></td></tr></table></figure></p>
<p>生成树如下：<br><img src="http://upload-images.jianshu.io/upload_images/1863202-0377acaefc8ac97d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="C4,5生成的决策树"></p>
<h2 id="3、CART算法"><a href="#3、CART算法" class="headerlink" title="3、CART算法"></a>3、CART算法</h2><p>CART(Classification and Regression Tree，分类与回归树)。<br>主要函数：</p>
<blockquote>
<p>tree()</p>
</blockquote>
<p>准备工作：</p>
<blockquote>
<p>> install.packages(‘tree’)<br>> library(tree)</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置窗口参数</span></span><br><span class="line">&gt; oldpar=par(mar=c(<span class="number">3</span>,<span class="number">3</span>,<span class="number">1.5</span>,<span class="number">1</span>),mgp=c(<span class="number">1.5</span>,<span class="number">0.5</span>,<span class="number">0</span>),cex=<span class="number">0.7</span>)</span><br><span class="line">&gt; data(iris)</span><br><span class="line"><span class="comment">#对品种进行CART分类</span></span><br><span class="line">&gt; ir.tr=tree(Species~.,iris)</span><br><span class="line">&gt; summary(ir.tr)</span><br><span class="line"><span class="comment">#画决策树图</span></span><br><span class="line">&gt; plot(ir.tr):text(ir.tr)</span><br></pre></td></tr></table></figure></p>
<p>生成树如下：<br><img src="http://upload-images.jianshu.io/upload_images/1863202-060c899e0b5b0022.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="CART生成的决策树"></p>
<h2 id="4、BP神经网络算法"><a href="#4、BP神经网络算法" class="headerlink" title="4、BP神经网络算法"></a>4、BP神经网络算法</h2><p>主要函数：</p>
<blockquote>
<p>nnet()</p>
</blockquote>
<p>准备工作：</p>
<blockquote>
<p>> install.packages(‘nnet’)<br>> library(nnet)</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt; data(iris3)</span><br><span class="line">&gt; ir&lt;-rbind(iris3[,,<span class="number">1</span>],iris3[,,<span class="number">2</span>],iris3[,,<span class="number">3</span>])</span><br><span class="line">&gt; targets&lt;-class.ind(c(rep(<span class="string">"s"</span>,<span class="number">50</span>),rep(<span class="string">"c"</span>,<span class="number">50</span>),rep(<span class="string">"v"</span>,<span class="number">50</span>)))</span><br><span class="line"><span class="comment">#抽取25个样本</span></span><br><span class="line">&gt; samp&lt;-c(sample(<span class="number">1</span>:<span class="number">50</span>,<span class="number">25</span>),sample(<span class="number">51</span>:<span class="number">100</span>,<span class="number">25</span>),sample(<span class="number">101</span>:<span class="number">150</span>,<span class="number">25</span>))</span><br><span class="line">&gt; ir1&lt;-nnet(ir[samp,],targets[samp,],size=<span class="number">2</span>,rang=<span class="number">0.1</span>,decay=<span class="number">5e-4</span>,maxit=<span class="number">200</span>)</span><br><span class="line">&gt; test.c1&lt;-<span class="keyword">function</span>(true,pred)&#123;</span><br><span class="line">+ true&lt;-max.col(true)</span><br><span class="line">+ cres&lt;-max.col(pred)</span><br><span class="line">+ table(true,cres)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#对样本以外的数据的测试</span></span><br><span class="line">&gt; test.c1(targets[-samp,],predict(ir1,ir[-samp,]))</span><br></pre></td></tr></table></figure></p>
<h1 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h1><h2 id="1、K-means算法"><a href="#1、K-means算法" class="headerlink" title="1、K-means算法"></a>1、K-means算法</h2><p>K-means算法是典型的基于距离的聚类算法，采用距离作为相似性的评价指标，即认为两个对象的距离越近，其相似度就越大。</p>
<p>主要函数：</p>
<blockquote>
<p>kmeans()</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#随机生成样本数据</span></span><br><span class="line">&gt; x&lt;-rbind(matrix(rnorm(<span class="number">10000</span>,sd=<span class="number">0.3</span>),ncol=<span class="number">10</span>),matrix(rnorm(<span class="number">10000</span>,mean=<span class="number">1</span>,sd=<span class="number">0.3</span>),ncol=<span class="number">10</span>))</span><br><span class="line">&gt; colnames(x)&lt;-c(<span class="string">"x1"</span>,<span class="string">"x2"</span>,<span class="string">"x3"</span>,<span class="string">"x4"</span>,<span class="string">"x5"</span>,<span class="string">"x6"</span>,<span class="string">"x7"</span>,<span class="string">"x8"</span>,<span class="string">"x9"</span>,<span class="string">"x10"</span>)</span><br><span class="line"><span class="comment">#调用K-means算法</span></span><br><span class="line">&gt; c1&lt;-Kmeans(x,<span class="number">2</span>)</span><br><span class="line">&gt; pch1=rep(<span class="string">"1"</span>,<span class="number">1000</span>)</span><br><span class="line">&gt; pch2=rep(<span class="string">"2"</span>,<span class="number">1000</span>)</span><br><span class="line">&gt; plot(x,col=c1$cluster,pch=c(pch1,pch2))</span><br><span class="line">&gt; points(c1$centers,col=<span class="number">3</span>,pch=<span class="string">"*"</span>,cex=<span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="2、PAM算法"><a href="#2、PAM算法" class="headerlink" title="2、PAM算法"></a>2、PAM算法</h2><p>PAM(Partitioning around Medoid，围绕中心点的划分)是最早提出的k-medoids算法之一。它试图对n个对象给出k个划分。最初随机选择k个中心点后，该算法反复地试图找出更好的中心点。</p>
<p>主要函数：</p>
<blockquote>
<p>pam()</p>
</blockquote>
<p>准备工作：</p>
<blockquote>
<p>> library(cluster)</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; pamx=pam(x,<span class="number">2</span>)</span><br><span class="line">&gt; summary(pamx)</span><br><span class="line">&gt; plot(pamx,main=<span class="string">"pam效果图"</span>)   <span class="comment">#数据集同上</span></span><br></pre></td></tr></table></figure></p>
<h2 id="3、Clara算法"><a href="#3、Clara算法" class="headerlink" title="3、Clara算法"></a>3、Clara算法</h2><p>主要思想：不考虑整个数据集合，选择实际数据的一小部分作为数据的样本，然后用PAM方法从样本中选择中心点。如果样本是以随机形式选取的，它应当足以代表原来的数据集合。从中选出的代表对象（中心点）很可能与从整个数据集合中选出的非常近似Clara抽取数据集合的多个样本，对每个样本应用PAM算法，返回最好的聚类结果作为输出。</p>
<p>主要函数：</p>
<blockquote>
<p>clara()</p>
</blockquote>
<p>准备工作：</p>
<blockquote>
<p>> library(cluster)</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; clarax=clara(x,<span class="number">2</span>)</span><br><span class="line">&gt; clarax</span><br><span class="line">&gt; clarax$clusinfo</span><br><span class="line">&gt; plot(clarax,main=<span class="string">"clara图"</span>)  <span class="comment">#数据集同上</span></span><br></pre></td></tr></table></figure></p>
<h1 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h1><h2 id="1、AGNES算法与DIANA算法"><a href="#1、AGNES算法与DIANA算法" class="headerlink" title="1、AGNES算法与DIANA算法"></a>1、AGNES算法与DIANA算法</h2><p>AGNES(Agglomerative Nesting)算法是凝聚的层次聚类方法。最初将每个对象作为一个簇，然后这些簇根据某些准则一步步地合并，直到所有的对象最终合并到一个簇中或某个终结条件被满足。<br>DIANA(Divisive ANAlysis)算法是分裂的层次聚类方法。采用自顶向下的策略，它首先将所有对象置于一个簇中，然后逐渐细分为越来越小的簇，直到每个对象自成一簇或某个终结条件被满足。</p>
<p>主要函数：</p>
<blockquote>
<p>agnes()、diana()</p>
</blockquote>
<p>准备工作：</p>
<blockquote>
<p>> library(cluster)</p>
</blockquote>
<p>实例：<br>AGNES和DIANA算法的比较<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将图形显示区划为两部分</span></span><br><span class="line">&gt; par(mfrow=c(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">&gt; data(flower)</span><br><span class="line">&gt; dai.f=daisy(flower,type=list(asymm=<span class="number">3</span>,ordratio=<span class="number">7</span>))</span><br><span class="line">&gt; agn.f=agnes(dai.f,method=<span class="string">"ward"</span>)</span><br><span class="line">&gt; plot(agn.f,which.plot=<span class="number">2</span>,cex=<span class="number">0.7</span>,yaxt=<span class="string">"n"</span>,main=<span class="string">"agnes算法的聚类图"</span>)</span><br><span class="line">&gt; dia.f=diana(dai.f)  <span class="comment">#注意这里dia.f与dai.f不同</span></span><br><span class="line">&gt; plot(dia.f,which.plot=<span class="number">2</span>,main=<span class="string">"diana算法的聚类图"</span>)</span><br></pre></td></tr></table></figure></p>
<p>结果图如下：<br><img src="http://upload-images.jianshu.io/upload_images/1863202-2128ea9d6676999a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="agnes与diana算法的比较(这个图画的有点丑，大家可以自己试下。。。)"></p>
<h1 id="基于密度聚类"><a href="#基于密度聚类" class="headerlink" title="基于密度聚类"></a>基于密度聚类</h1><p>主要思想：只要临近区域的密度（对象或数据点的数目）超过某个阀值，就继续聚类。</p>
<p>优点：可以过滤“噪声”孤立点数据，发现任意形状的簇。</p>
<h2 id="1、DBSCAN算法"><a href="#1、DBSCAN算法" class="headerlink" title="1、DBSCAN算法"></a>1、DBSCAN算法</h2><p>DBSCAN(Density-Based Spatial Clustering of Application with Noise)是一个有代表性的基于密度的方法，它根据一个密度阀值来控制簇的增长。</p>
<p>主要函数：</p>
<blockquote>
<p>DBSCAN()</p>
</blockquote>
<p>准备工作：</p>
<blockquote>
<p>> library(cluster)</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; dflower&lt;-daisy(flower,type=list(asymm=c(<span class="string">"V1"</span>,<span class="string">"V3"</span>),symm=<span class="number">2</span>,norminal=<span class="number">4</span>,ordinal=c(<span class="number">5</span>,<span class="number">6</span>),ordratio=<span class="number">7</span>,logratio=<span class="number">8</span>))</span><br><span class="line">&gt; DBF=DBSCAN(dflower,eps=<span class="number">0.65</span>,MinPts=<span class="number">5</span>,distances=<span class="literal">T</span>)</span><br><span class="line">&gt; DBF</span><br></pre></td></tr></table></figure></p>
<h1 id="基于模型聚类"><a href="#基于模型聚类" class="headerlink" title="基于模型聚类"></a>基于模型聚类</h1><h2 id="1、COBWEB算法"><a href="#1、COBWEB算法" class="headerlink" title="1、COBWEB算法"></a>1、COBWEB算法</h2><p>COBWEB是一种流行的简增量概念聚类算法。它以一个分类树的形式创建层次聚类，每个节点对应一个概念，包含该概念的一个概率描述，概述被分在该节点下的对象。</p>
<p>主要函数：</p>
<blockquote>
<p>Cobweb()</p>
</blockquote>
<p>准备工作：</p>
<blockquote>
<p>> install.packages(‘RWeka’)<br>> library(RWeka)</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; com=rbind(cbind(rnorm(<span class="number">20</span>,<span class="number">0</span>,<span class="number">0.5</span>),rnorm(<span class="number">20</span>,<span class="number">0</span>,<span class="number">0.5</span>)),cbind(rnorm(<span class="number">30</span>,<span class="number">5</span>,<span class="number">0.5</span>),rnorm(<span class="number">30</span>,<span class="number">5</span>,<span class="number">0.5</span>)))</span><br><span class="line">&gt; clas=factor(rep(<span class="number">2</span>:<span class="number">1</span>,c(<span class="number">20</span>,<span class="number">30</span>)))</span><br><span class="line">&gt; dcom=data.frame(com,clas)</span><br><span class="line">&gt; c1&lt;-Cobweb(dcom)</span><br><span class="line">&gt; c1</span><br><span class="line">&gt; c1$class_ids</span><br><span class="line">&gt; table(predict(c1),dcom$clas)</span><br></pre></td></tr></table></figure></p>
<h1 id="模糊聚类"><a href="#模糊聚类" class="headerlink" title="模糊聚类"></a>模糊聚类</h1><h2 id="1、FCM算法"><a href="#1、FCM算法" class="headerlink" title="1、FCM算法"></a>1、FCM算法</h2><p>FCM(Fuzzy C-Means)算法是一个模糊聚类算法，不同于硬划分，模糊聚类方法是一个软划分。对于模糊集来说，一个数据点都是以一定程度属于某个类，也可以同时以不周的程度属于几个类。</p>
<p>主要函数：</p>
<blockquote>
<p>fanny()</p>
</blockquote>
<p>准备工作：</p>
<blockquote>
<p>> library(cluster)</p>
</blockquote>
<p>实例：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; z=rbind(cbind(rnorm(<span class="number">100</span>,<span class="number">0</span>,<span class="number">0.5</span>),rnorm(<span class="number">100</span>,<span class="number">0</span>,<span class="number">0.5</span>)),cbind(rnorm(<span class="number">150</span>,<span class="number">5</span>,<span class="number">0.5</span>),rnorm(<span class="number">150</span>,<span class="number">5</span>,<span class="number">0.5</span>),cbind(rnorm(<span class="number">300</span>,<span class="number">3.2</span>,<span class="number">0.5</span>),rnorm(<span class="number">300</span>,<span class="number">3.2</span>,<span class="number">0.5</span>))))</span><br><span class="line">&gt; z</span><br><span class="line">&gt; fannyz=fanny(z,<span class="number">3</span>,metric=<span class="string">"SqEuclidean"</span>)</span><br><span class="line">&gt; summary(fannyz)</span><br><span class="line">&gt; plot(fannyz,main=<span class="string">"模糊算法聚类图"</span>)</span><br></pre></td></tr></table></figure></p>
<p>参考文献<br><em>方匡南. 基于数据挖掘的分类和聚类算法研究及R语言实现[D]. 暨南大学, 2007.</em></p>

      
    </div>

    <div>
      
        
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/R语言/" rel="tag">#R语言</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/04/05/数据预处理/" rel="next" title="数据预处理">
                <i class="fa fa-chevron-left"></i> 数据预处理
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/04/26/前端技术：从一个悼念页面开始/" rel="prev" title="前端学习：从一个悼念页面开始">
                前端学习：从一个悼念页面开始 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/04/11/数据挖掘算法的R语言实现/"
           data-title="数据挖掘算法的R语言实现" data-url="https://longfengno1.github.io/2016/04/11/数据挖掘算法的R语言实现/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/head.png"
               alt="Xiao" />
          <p class="site-author-name" itemprop="name">Xiao</p>
          <p class="site-description motion-element" itemprop="description">True mastery of any skill takes a lifetime.</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">4</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/longfengno1" target="_blank">
                  
                    <i class="fa fa-globe"></i> github
                  
                </a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="http://creativecommons.org/licenses/by-nc-sa/4.0" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        
        <div class="links-of-blogroll motion-element">
          
        </div>

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator">
            <i class="fa fa-angle-double-up"></i>
          </div>
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类"><span class="nav-number">2.</span> <span class="nav-text">分类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、KNN算法"><span class="nav-number">2.1.</span> <span class="nav-text">1、KNN算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、决策树算法（C4-5）"><span class="nav-number">2.2.</span> <span class="nav-text">2、决策树算法（C4,5）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、CART算法"><span class="nav-number">2.3.</span> <span class="nav-text">3、CART算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4、BP神经网络算法"><span class="nav-number">2.4.</span> <span class="nav-text">4、BP神经网络算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#聚类"><span class="nav-number">3.</span> <span class="nav-text">聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、K-means算法"><span class="nav-number">3.1.</span> <span class="nav-text">1、K-means算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、PAM算法"><span class="nav-number">3.2.</span> <span class="nav-text">2、PAM算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、Clara算法"><span class="nav-number">3.3.</span> <span class="nav-text">3、Clara算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#层次聚类"><span class="nav-number">4.</span> <span class="nav-text">层次聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、AGNES算法与DIANA算法"><span class="nav-number">4.1.</span> <span class="nav-text">1、AGNES算法与DIANA算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基于密度聚类"><span class="nav-number">5.</span> <span class="nav-text">基于密度聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、DBSCAN算法"><span class="nav-number">5.1.</span> <span class="nav-text">1、DBSCAN算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基于模型聚类"><span class="nav-number">6.</span> <span class="nav-text">基于模型聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、COBWEB算法"><span class="nav-number">6.1.</span> <span class="nav-text">1、COBWEB算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模糊聚类"><span class="nav-number">7.</span> <span class="nav-text">模糊聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、FCM算法"><span class="nav-number">7.1.</span> <span class="nav-text">1、FCM算法</span></a></li></ol></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator">
            <i class="fa fa-angle-double-down"></i>
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiao</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

<script type="text/javascript" src="/js/src/tw_cn.js"></script>
<script type="text/javascript">
var defaultEncoding = 2; //网站编写字体是否繁体，1-繁体，2-简体
var translateDelay = 0; //延迟时间,若不在前, 要设定延迟翻译时间, 如100表示100ms,默认为0
var cookieDomain = "https://longfengno1.github.io/"; //Cookie地址, 一定要设定, 通常为你的网址
var msgToTraditionalChinese = "繁體"; //此处可以更改为你想要显示的文字
var msgToSimplifiedChinese = "简体"; //同上，但两处均不建议更改
var translateButtonId = "translateLink"; //默认互换id
translateInitilization();
</script>
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>



      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  


  




<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=0.5.0"></script>



  
  
<script type="text/javascript" src="/js/src/scrollspy.js?v=0.5.0"></script>

<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 1 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = NexT.utils.escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    NexT.motion.middleWares.sidebar = function () {
      var $tocContent = $('.post-toc-content');

      if (CONFIG.sidebar.display === 'post' || CONFIG.sidebar.display === 'always') {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          NexT.utils.displaySidebar();
        }
      }
    };
  });
</script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"longfengno1"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
  





  
  
  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("LqnBQ25KPxK3MzMY0bvMsSql-gzGzoHsz", "7UzPz5b6tmgQM8twL0kCspnl");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
  
  <script type="text/javascript" src="http://apps.bdimg.com/libs/jquery-lazyload/1.9.5/jquery.lazyload.min.js"></script>
    <script type="text/javascript">
      jQuery(function() {          
          jQuery("#post img").lazyload({
            placeholder:"http://www.arao.me/loading.gif",
              effect:"fadeIn"
            });
          });
  </script>

</body>
</html>
